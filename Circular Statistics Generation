# -------------------------------------------------
# Circular Mean Calculation for Tweet Times
# -------------------------------------------------
# This function computes the circular (angular) mean of Tweet posting times for each participant.
# Intended for use with participant-level datasets where columns 0-23 represent Tweet counts for each hour.
#
# Application:
# - Designed to be called within the final_generation linkage function.
# - Generates participant-wise summary metrics for temporal Tweet behaviour.
# -------------------------------------------------

import math
import pandas as pd
import numpy as np

def circ_mean_round(data_f, mean_ang):
    """
    Computes circular mean Tweet posting time for each participant.

    Workflow:
    1. For each participant (row in data_f), expand hourly Tweet counts (columns 0-23) into a list of hour angles.
    2. Convert hour to radians: angle = (hour/24) * 2Ï€.
    3. Concatenate all hour angles for all Tweets by the participant.
    4. Compute mean resultant vector (C, S), then derive circular mean angle.
    5. Accounts for edge cases (no Tweets, zero vectors).
    6. Appends mean angle value to mean_ang list.

    Parameters:
    - data_f: DataFrame, participant-level wide form with hourly Tweet columns.
    - mean_ang: list, collects mean angle value per participant (order matches data_f rows).

    Returns: None (results added to mean_ang list).
    """
    for ind in data_f['row_num']:
        # Build list of angles for all Tweets by participant, hour-by-hour
        x_all = []
        for hour in range(24):
            angle = (hour / 24) * (2 * math.pi)
            x_all.extend([angle] * int(data_f.iloc[ind][hour]))
        angles = x_all
        
        # Calculate mean cosine (C) and sine (S) of angles
        mean_data = pd.DataFrame(angles, columns=['angles_r'])
        mean_data['C'] = np.cos(mean_data['angles_r'])
        mean_data['S'] = np.sin(mean_data['angles_r'])
        
        if len(mean_data) != 0:
            C = mean_data['C'].sum() / len(mean_data)
            S = mean_data['S'].sum() / len(mean_data)
            # Determine circular mean angle based on quadrant
            if S >= 0 and C > 0:
                mean_angle = np.arctan(S / C)
            elif C < 0:
                mean_angle = np.arctan(S / C) + math.pi
            elif S < 0 and C > 0:
                mean_angle = np.arctan(S / C) + 2 * math.pi
            elif S > 0 and C == 0:
                mean_angle = 0.5 * math.pi
            elif S < 0 and C == 0:
                mean_angle = 1.5 * math.pi
            elif S == 0 and C == 0:
                mean_angle = None
            mean_ang.append(mean_angle)
        else:
            mean_ang.append(None)

# -------------------------------------------------
# Integration with Data Linkage and Saving Procedure
# -------------------------------------------------

def final_generation(df, name):
    """
    Runs participant-level metric generation, including circular mean, for Tweet time window analysis.

    Steps:
    - Generates hourly Tweet count columns and total Tweet counts ('total_tweets').
    - Adds row tracking variable ('row_num').
    - Runs circular mean calculation per participant (via circ_mean_round).
    - Adds mean angle as new column to dataframe.
    - Merges enriched Tweet metrics with ALSPAC survey data and generates participant/generation labels.
    - Saves final merged dataset to disk.
    """
    data_gen(df, 'final_df')
    global final_df
    # Keep linker and Tweet counts for hours 0-23
    final_df = final_df[['linker'] + list(range(24))]
    
    # Calculate total Tweets per participant
    final_df['total_tweets'] = final_df.loc[:, range(24)].sum(axis=1)
    
    # Row number for reference
    final_df['row_num'] = np.arange(len(final_df))
    
    # ---- Circular Mean Calculation ----
    mean_ang = []
    circ_mean_round(final_df, mean_ang)
    final_df['Mean Angle'] = mean_ang    # New column for mean posting angle
    
    # Prepare linkage and saving
    link = final_df[['linker','Mean Angle', 'total_tweets']]
    final_d = surv.merge(final_df)
    final_d = final_d.sort_values(by=['row_num'])
    
    # Compose participant linkage labels
    final_d['aln'] = final_d['aln'].astype(str)
    final_d['linker'] = final_d['aln'] + ' ' + final_d['qlet']
    
    # Assign generation classification
    final_d['generation'] = None
    final_d.loc[final_d['qlet'].isin(['A', 'B']), 'generation'] = 'G1'
    final_d.loc[final_d['qlet'].isin(['P', 'M']), 'generation'] = 'G0'
    
    print(final_d)
    final_d.to_csv(f'C:/Users/ta20395/TD/Second Harvest Data/{name}.csv')
